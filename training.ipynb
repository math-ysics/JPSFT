{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giM74oK1rRIH",
        "outputId": "c71330ff-2ca4-4438-fade-e7b897975212"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "%rm -rf LLaMA-Factory\n",
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "%cd LLaMA-Factory\n",
        "%ls\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
        "!pip uninstall -y jax\n",
        "!pip install -e .[torch,bitsandbytes,liger-kernel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZkN-ktlsnrdU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "try:\n",
        "  assert torch.cuda.is_available() is True\n",
        "except AssertionError:\n",
        "  print(\"Incorrect setup.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_fvMBsQHJc",
        "outputId": "411d4e03-71de-47df-8f6d-82d42432c098"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "\n",
        "DATASET_PATH = \"/content/drive/My Drive/alpaca_final.json\"\n",
        "\n",
        "with open(DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "  dataset = json.load(f)\n",
        "\n",
        "!cp \"/content/drive/My Drive/alpaca_final.json\" \"/content/LLaMA-Factory/data/alpaca_final.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5mEBJomyS9O",
        "outputId": "b3e9e47e-b143-4bcc-82f0-57c3806b9527"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4MCiQjuQJAz9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/LLaMA-Factory/data/dataset_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    dataset_info = json.load(f)\n",
        "\n",
        "dataset_info[\"alpaca_final\"] = {\n",
        "    \"file_name\": \"alpaca_final.json\",\n",
        "    \"language\": \"ja\",\n",
        "    \"task\": \"instruction\",\n",
        "    \"license\": \"unknown\"\n",
        "}\n",
        "\n",
        "with open(\"/content/LLaMA-Factory/data/dataset_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset_info, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS0Qk5OR0i4Q",
        "outputId": "1eb7dd97-018c-45c0-d714-e33d6dbc9c5c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  stage=\"sft\",\n",
        "  do_train=True,\n",
        "  model_name_or_path=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "  dataset=\"identity,alpaca_final\",\n",
        "  template=\"llama3\",\n",
        "  finetuning_type=\"lora\",\n",
        "  lora_target=\"all\",\n",
        "  lora_rank=512,\n",
        "  output_dir=\"llama3_lora\",\n",
        "  per_device_train_batch_size=16,\n",
        "  gradient_accumulation_steps=1,\n",
        "  lr_scheduler_type=\"cosine\",\n",
        "  logging_steps=10,\n",
        "  warmup_ratio=0.1,\n",
        "  save_steps=1000,\n",
        "  learning_rate=5e-5,\n",
        "  num_train_epochs=3.0,\n",
        "  max_samples=float('inf'),\n",
        "  max_grad_norm=1.0,\n",
        "  loraplus_lr_ratio=16.0,\n",
        "  fp16=True,\n",
        ")\n",
        "\n",
        "json.dump(args, open(\"train_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "\n",
        "!llamafactory-cli train train_llama3.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMojogHbaOZF",
        "outputId": "7ddd89de-88ed-47f1-afc0-f61af3ae6322"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  model_name_or_path=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "  adapter_name_or_path=\"llama3_lora\",\n",
        "  template=\"llama3\",\n",
        "  finetuning_type=\"lora\",\n",
        "  export_dir=\"llama3_lora_merged\",\n",
        "  export_size=2,\n",
        "  export_device=\"cpu\",\n",
        ")\n",
        "\n",
        "json.dump(args, open(\"merge_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "\n",
        "!llamafactory-cli export merge_llama3.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O40_yeL80oGI",
        "outputId": "5874634e-dd72-4bd5-a4bd-944b35854e03"
      },
      "outputs": [],
      "source": [
        "%cd /content/LLaMA-Factory/llama3_lora_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoWUMQ5j0o0O",
        "outputId": "15d2dc97-680c-4184-9ef9-2908f5ae93d0"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "O48LRYayQ8oM"
      },
      "outputs": [],
      "source": [
        "!cp tokenizer.json /content/drive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
